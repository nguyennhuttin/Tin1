create web directory ./checkpoints/collage_test_cycle_gan_3rdloss_wandb/web...
learning rate 0.0002000 -> 0.0002000
/fs02/zd26/collage_main/Tin/pytorch-CycleGAN-and-pix2pix/.venv/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
(epoch: 1, iters: 100, time: 1.346, data: 0.949) D_A: 0.253 G_A: 0.421 cycle_A: 1.808 idt_A: 0.286 D_B: 0.847 G_B: 0.349 cycle_B: 0.651 idt_B: 1.248
(epoch: 1, iters: 200, time: 1.356, data: 0.002) D_A: 0.297 G_A: 0.801 cycle_A: 2.859 idt_A: 0.377 D_B: 0.177 G_B: 0.641 cycle_B: 0.788 idt_B: 1.659
(epoch: 1, iters: 300, time: 1.356, data: 0.002) D_A: 0.210 G_A: 0.398 cycle_A: 1.937 idt_A: 0.243 D_B: 0.280 G_B: 0.451 cycle_B: 0.566 idt_B: 1.156
(epoch: 1, iters: 400, time: 26.083, data: 0.002) D_A: 0.175 G_A: 0.391 cycle_A: 1.053 idt_A: 0.209 D_B: 0.479 G_B: 0.456 cycle_B: 0.468 idt_B: 0.503
(epoch: 1, iters: 500, time: 1.352, data: 0.002) D_A: 0.362 G_A: 0.108 cycle_A: 0.753 idt_A: 0.260 D_B: 0.402 G_B: 0.748 cycle_B: 0.531 idt_B: 0.309
(epoch: 1, iters: 600, time: 1.349, data: 0.002) D_A: 0.120 G_A: 0.267 cycle_A: 0.673 idt_A: 0.236 D_B: 0.238 G_B: 0.361 cycle_B: 0.450 idt_B: 0.335
(epoch: 1, iters: 700, time: 1.348, data: 0.002) D_A: 0.082 G_A: 0.449 cycle_A: 2.237 idt_A: 0.275 D_B: 0.119 G_B: 0.761 cycle_B: 1.142 idt_B: 1.000
(epoch: 1, iters: 800, time: 1.512, data: 0.002) D_A: 0.266 G_A: 0.339 cycle_A: 1.211 idt_A: 0.342 D_B: 0.169 G_B: 0.419 cycle_B: 0.560 idt_B: 0.557
(epoch: 1, iters: 900, time: 1.356, data: 0.002) D_A: 0.123 G_A: 1.423 cycle_A: 5.564 idt_A: 0.260 D_B: 0.032 G_B: 0.565 cycle_B: 0.454 idt_B: 2.622
(epoch: 1, iters: 1000, time: 1.353, data: 0.002) D_A: 0.320 G_A: 1.186 cycle_A: 0.864 idt_A: 0.281 D_B: 0.157 G_B: 0.196 cycle_B: 0.520 idt_B: 0.476
(epoch: 1, iters: 1100, time: 1.351, data: 0.002) D_A: 0.159 G_A: 0.235 cycle_A: 0.980 idt_A: 0.222 D_B: 0.176 G_B: 0.401 cycle_B: 0.460 idt_B: 0.499
(epoch: 1, iters: 1200, time: 1.498, data: 0.002) D_A: 0.100 G_A: 0.370 cycle_A: 0.760 idt_A: 0.177 D_B: 0.297 G_B: 1.050 cycle_B: 0.413 idt_B: 0.350
(epoch: 1, iters: 1300, time: 1.350, data: 0.002) D_A: 0.253 G_A: 0.220 cycle_A: 0.659 idt_A: 0.232 D_B: 0.291 G_B: 0.735 cycle_B: 0.419 idt_B: 0.323
(epoch: 1, iters: 1400, time: 1.352, data: 0.002) D_A: 0.133 G_A: 0.707 cycle_A: 1.432 idt_A: 0.298 D_B: 0.074 G_B: 0.563 cycle_B: 0.575 idt_B: 0.598
(epoch: 1, iters: 1500, time: 1.349, data: 0.002) D_A: 0.060 G_A: 0.381 cycle_A: 0.683 idt_A: 0.166 D_B: 0.175 G_B: 0.286 cycle_B: 0.323 idt_B: 0.414
(epoch: 1, iters: 1600, time: 1.515, data: 0.002) D_A: 0.115 G_A: 1.244 cycle_A: 1.235 idt_A: 0.226 D_B: 0.019 G_B: 0.824 cycle_B: 0.379 idt_B: 0.541